{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1tD-qCNspaL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible improvements\n",
    "\n",
    "* Go 3D (e.g. V-Net)\n",
    "* Change model parameters (more down/up layers)\n",
    "* Fix data loader\n",
    " - Detect empty slices\n",
    " - Detect slices without matching labels\n",
    " - Data augmentation (cropping, deform)\n",
    "* Try other optimizers\n",
    "* Tune hyperparameters\n",
    " - k-fold-Validation\n",
    "* One Channel, Transfer Learning, Add another layer later\n",
    "* Try other datasets (hippocampus, liver)\n",
    "* Experiment with Loss Functions\n",
    " - https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/\n",
    " - https://github.com/JunMa11/SegLoss\n",
    "* Accuracy metric (measure overlay predicted/true)\n",
    "* Participate in Challenge\n",
    "\n",
    "# Orga\n",
    "* Comment code\n",
    "* Try on Colab\n",
    "* Upload to GitHub\n",
    "* Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "culHh9bgspaq"
   },
   "outputs": [],
   "source": [
    "# From d2l.ai\n",
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3miZrQ7spbE"
   },
   "outputs": [],
   "source": [
    "class BRATS(td.Dataset):\n",
    "    def __init__(self, data_dir, train):\n",
    "        super(BRATS).__init__()\n",
    "        self.train = train\n",
    "        self.data_dir = data_dir\n",
    "        self.data = []\n",
    "        self.filenames = []\n",
    "        match_brats_filename = re.compile(r\"^BRATS_[0-9]{3}.nii.gz$\")\n",
    "        if self.train:\n",
    "            self.labels = []\n",
    "            image_dir = os.path.join(self.data_dir, 'imagesTr')\n",
    "            label_dir = os.path.join(self.data_dir, 'labelsTr')\n",
    "        else:\n",
    "            image_dir = os.path.join(self.data_dir, 'imagesTs')\n",
    "\n",
    "        for fn in os.listdir(image_dir):\n",
    "            abs_fn = os.path.join(image_dir, fn)\n",
    "            if os.path.isfile(abs_fn):\n",
    "                #print(fn)\n",
    "                if match_brats_filename.match(fn):\n",
    "                    nifti_img = nib.load(abs_fn)\n",
    "                    #nifti_data = nifti_img.get_fdata()\n",
    "                    self.data.append(nifti_img)\n",
    "                    self.filenames.append(abs_fn)\n",
    "        \n",
    "        self.slice_offset_start = 40\n",
    "        self.slice_offset_end = 40\n",
    "        self.slice_count = 155 - self.slice_offset_start - self.slice_offset_end\n",
    "        \n",
    "        self.transform_cache = {}\n",
    "        \n",
    "        self.num_files = len(self.data)\n",
    "        print('Loaded {} files'.format(self.num_files))\n",
    "        if self.train:\n",
    "            for fn in os.listdir(image_dir):\n",
    "                abs_fn = os.path.join(label_dir, fn)\n",
    "                if os.path.isfile(abs_fn) and match_brats_filename.match(fn):\n",
    "                    nifti_img = nib.load(abs_fn)\n",
    "                    self.labels.append(nifti_img)\n",
    "            print('Loaded {} labels'.format(len(self.labels)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_files * self.slice_count\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_index = idx // self.slice_count\n",
    "        slice_index = self.slice_offset_start + idx % self.slice_count\n",
    "        #print('sample_index = {}, slice_index = {}'.format(sample_index, slice_index)\n",
    "        \n",
    "        nifti_data = np.asarray(self.data[sample_index].dataobj[:, :, slice_index, :])\n",
    "        nifti_slice = torch.from_numpy(np.copy(nifti_data)).transpose(0,2)\n",
    "        \n",
    "        if idx in self.transform_cache:\n",
    "            nifti_normalize = self.transform_cache[idx]\n",
    "        else:\n",
    "            nifti_norm = np.linalg.norm(nifti_slice)\n",
    "            if (nifti_norm > 0.0):\n",
    "                nifti_mean = torch.mean(nifti_slice, dim=(1,2)) +1e-9\n",
    "                nifti_std = torch.std(nifti_slice, dim=(1,2)) +1e-9\n",
    "                #print('sampleidx = {}, iidx = {}, fn = {}, mean = {}, std = {}, shape = {}'.format(idx, sample_index, self.filenames[sample_index], nifti_mean, nifti_std, nifti_slice.shape))\n",
    "                nifti_normalize = torchvision.transforms.Normalize(nifti_mean, nifti_std)\n",
    "            else:\n",
    "                nifti_normalize = None\n",
    "            self.transform_cache[idx] = nifti_normalize\n",
    "        \n",
    "        if nifti_normalize is not None:\n",
    "            nifti_slice = nifti_normalize(nifti_slice)\n",
    "        \n",
    "        if self.train:\n",
    "            label_data = np.asarray(self.labels[sample_index].dataobj[:, :, slice_index])\n",
    "            label_slice = torch.from_numpy(np.copy(label_data)).transpose(0,1)\n",
    "\n",
    "        return nifti_slice, label_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "8DEFrbFUspbX",
    "outputId": "8ebd411a-f7df-4f3b-c3f5-ffaedb7daeae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 484 files\n",
      "Loaded 484 labels\n",
      "Loaded 266 files\n"
     ]
    }
   ],
   "source": [
    "brats_train = BRATS('Task01_BrainTumour', train=True)\n",
    "brats_test = BRATS('Task01_BrainTumour', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKlVPNKmspbt"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 6\n",
    "\n",
    "train_iter = td.DataLoader(brats_train, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = td.DataLoader(brats_test, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbmZfPN8spcA"
   },
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(Down, self).__init__()\n",
    "        assert(size > 2)\n",
    "        size2 = 1 << size\n",
    "        size2m1 = 1 << (size - 1)\n",
    "\n",
    "        self.down = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(size2m1, size2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(size2, size2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(size2),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print('Xs = {}'.format(X.shape))\n",
    "        return self.down(X)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, size, padding=0):\n",
    "        super(Up, self).__init__()\n",
    "        \n",
    "        assert(size > 2)\n",
    "        assert(padding >= 0)\n",
    "        \n",
    "        size2 = 1 << size # 2^10 = 1024\n",
    "        size2m1 = 1 << (size - 1) # 2^9 = 512\n",
    "        size2p1 = 1 << (size + 1) # 2^11 = 2048\n",
    "        \n",
    "        padding_top = padding // 2\n",
    "        padding_bottom = padding - padding_top\n",
    "        padding_left = padding // 2\n",
    "        padding_right = padding - padding_left\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(size2p1, size2, kernel_size=2, stride=2)\n",
    "        #self.up = nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2)\n",
    "        self.pad = nn.ReflectionPad2d(padding=(padding_left, padding_right, padding_top, padding_bottom))\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(size2p1, size2, kernel_size=3),\n",
    "            nn.BatchNorm2d(size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(size2, size2, kernel_size=3),\n",
    "            nn.BatchNorm2d(size2),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, X, Z):        \n",
    "        X = self.up(X)\n",
    "        \n",
    "        #diff_x = Z.size()[2] - X.size()[2]\n",
    "        #diff_y = Z.size()[3] - X.size()[3]\n",
    "        #pad_x = diff_x >> 1\n",
    "        #pad_y = diff_y >> 1\n",
    "        #print('diff_x = {}, diff_y = {}'.format(diff_x, diff_y))\n",
    "        #X = F.pad(X, pad=(pad_x, diff_x - pad_x, pad_y, diff_x - pad_y))\n",
    "\n",
    "        X = torch.cat([self.pad(X), Z], dim=1)\n",
    "        \n",
    "        return self.conv(X)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #self.num_inputs = num_inputs\n",
    "        self.input_channels = 4\n",
    "        \n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channels, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        # 64  -> 128\n",
    "        self.down2 = Down(7)\n",
    "        # 128 -> 256\n",
    "        self.down3 = Down(8)\n",
    "        # 256 -> 512\n",
    "        self.down4 = Down(9)\n",
    "        # 512 -> 1024\n",
    "        self.even5 = Down(10)\n",
    "        # 1024 -> 512\n",
    "        self.up4 = Up(9, 1)\n",
    "        # 512  -> 256\n",
    "        self.up3 = Up(8, 9)\n",
    "        # 256  -> 128\n",
    "        self.up2 = Up(7, 8)\n",
    "        self.up1 = Up(6, 8)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        downup = nn.Sequential(\n",
    "            self.down1,\n",
    "            self.down2,\n",
    "            self.down3,\n",
    "            self.down4,\n",
    "            self.even5,\n",
    "            self.up4,\n",
    "            self.up3,\n",
    "            self.up2,\n",
    "            self.up1\n",
    "            )\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.down1(X)\n",
    "        H2 = self.down2(H1)\n",
    "        H3 = self.down3(H2)\n",
    "        H4 = self.down4(H3)\n",
    "        H5 = self.even5(H4)\n",
    "        H6 = self.up4(H5, H4)\n",
    "        H7 = self.up3(H6, H3)\n",
    "        H8 = self.up2(H7, H2)\n",
    "        H9 = self.up1(H8, H1)\n",
    "        out = F.pad(self.out(H9), pad=(4, 4, 4, 4))\n",
    "        return out\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) in [nn.Conv2d, nn.ConvTranspose2d]:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/1249\n",
    "\n",
    "def dice_loss(pred, target):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = pred.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_criterion = nn.BCEWithLogitsLoss(reduction='mean', pos_weight=torch.Tensor([5.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, target):\n",
    "    return bce_criterion(pred, target) + dice_loss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEmGqmCdspcQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_E_BqaOspcd"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J11S4TCsspcr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (down1): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (even5): Down(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "#print(net)\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check():\n",
    "    X = torch.randn(size=(2, 4, 240, 240), dtype=torch.float32)\n",
    "    y = net(X)\n",
    "    \n",
    "check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euJjlHQCspc3"
   },
   "outputs": [],
   "source": [
    "#X = torch.randn(size=(8, 4, 240, 240), dtype=torch.float32)\n",
    "#for layer in net.downup:\n",
    "#    X = layer(X)\n",
    "#    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = torch.load('checkpoint_1599.pt', map_location=torch.device('cpu'))\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('checkpoint_sd.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "30QJl31bspdy",
    "outputId": "ae58099d-a3ad-44ce-c474-3a2770896161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing graph\n",
      "diff_x = 1, diff_y = 1\n",
      "diff_x = 9, diff_y = 9\n",
      "diff_x = 8, diff_y = 8\n",
      "diff_x = 8, diff_y = 8\n",
      "diff_x = 1, diff_y = 1\n",
      "diff_x = 9, diff_y = 9\n",
      "diff_x = 8, diff_y = 8\n",
      "diff_x = 8, diff_y = 8\n",
      "diff_x = 1, diff_y = 1\n",
      "diff_x = 9, diff_y = 9\n",
      "diff_x = 8, diff_y = 8\n",
      "diff_x = 8, diff_y = 8\n",
      "done\n",
      "Using device cpu\n",
      "total count = 36300, num_epochs = 50, per epoch = 726\n",
      "Total batches: 182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0ce30cd2f828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#l = criterion(y_hat, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-6083a0538736>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#X = X.reshape((-1, self.num_inputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mH1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mH2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mH3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 350\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_iter += 1\n",
    "batch_size=4\n",
    "writer = SummaryWriter('runs/brats3_{}_{}'.format(lr, run_iter))\n",
    "print('Writing graph')\n",
    "X = torch.randn(size=(2, 4, 240, 240), dtype=torch.float32)\n",
    "writer.add_graph(net, X)\n",
    "print('done')\n",
    "\n",
    "device = try_gpu()\n",
    "print('Using device {}'.format(device))\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "global_iter = 1\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "datasize = len(brats_train)\n",
    "data_per_epoch = int(math.floor(datasize/num_epochs))\n",
    "print('total count = {}, num_epochs = {}, per epoch = {}'.format(datasize, num_epochs, data_per_epoch))\n",
    "\n",
    "brats_train_perepoch = td.random_split(brats_train, torch.full(size=[num_epochs], fill_value=data_per_epoch, dtype=torch.int))\n",
    "\n",
    "for epoch in range(num_epochs-1): \n",
    "    train_loss_epoch = 0.0\n",
    "    \n",
    "    train_iter = td.DataLoader(brats_train_perepoch[epoch], batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = td.DataLoader(brats_train_perepoch[epoch+1], batch_size, shuffle=True, num_workers=num_workers)\n",
    "    #test_iter = td.DataLoader(brats_test, batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    batch_count = len(train_iter)\n",
    "    \n",
    "    print('Total batches: {}'.format(batch_count))\n",
    "    \n",
    "    for i, (X, y) in enumerate(train_iter): \n",
    "        global_iter += 1      \n",
    "        net.train()\n",
    "        \n",
    "        X = X.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        y_hat = net(X).squeeze(1)\n",
    "        \n",
    "        #l = criterion(y_hat, y)\n",
    "        bl = bce_criterion(y_hat, y)\n",
    "        dl = dice_loss(y_hat, y)\n",
    "        l = bl + dl\n",
    "        train_loss_epoch += float(l)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i > 0 and (i % 50 == 0):\n",
    "            print('saving checkpoint...')\n",
    "            torch.save(net, 'checkpoint_{}.pt'.format(i))\n",
    "            print('done')\n",
    "            for tag, value in net.named_parameters():\n",
    "                tag = tag.replace('.', '/')\n",
    "                writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_iter)\n",
    "                writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_iter)\n",
    "        \n",
    "        writer.add_scalar('batch_loss', float(l), global_iter)\n",
    "        writer.add_scalar('loss/total_loss', float(l), global_iter)\n",
    "        writer.add_scalar('loss/bce_loss', float(bl), global_iter)\n",
    "        writer.add_scalar('loss/dice_loss', float(dl), global_iter)\n",
    "        writer.add_images('masks/0_base', X[:,0:3,:,:], global_iter)\n",
    "        y_us = y.unsqueeze(1)\n",
    "        y_hat_us = y_hat.unsqueeze(1)\n",
    "        y_hat_us_sig = torch.sigmoid(y_hat_us) > 0.5\n",
    "        writer.add_images('masks/1_true', y_us, global_iter)\n",
    "        writer.add_images('masks/2_predicted', y_hat_us_sig, global_iter)\n",
    "        writer.add_images('extra/raw', y_hat_us, global_iter)\n",
    "        overlaid = torch.cat([y_hat_us_sig.float(), y_us, torch.zeros_like(y_us)], dim=1)\n",
    "        writer.add_images('extra/overlaid', overlaid, global_iter)\n",
    "        \n",
    "        writer.flush()\n",
    "    \n",
    "        print('batch {:4}/{} batchloss {}'.format(i, batch_count, float(l)))\n",
    "\n",
    "    train_loss_epoch /= batch_count\n",
    "    \n",
    "    writer.add_scalar('loss/train', train_loss_epoch, global_iter)\n",
    "  \n",
    "    net.eval()\n",
    "    test_loss_epoch = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_iter:\n",
    "            X_test = X_test.float().to(device)\n",
    "            y_test = y_test.float().to(device)\n",
    "            y_test_hat = net(X_test).squeeze(1)\n",
    "            b_l = criterion(y_test_hat, y_test) \n",
    "            test_loss_epoch += float(b_l)\n",
    "        test_loss_epoch /= len(test_iter)  \n",
    "        \n",
    "    writer.add_scalar('loss/test', test_loss_epoch, global_iter)\n",
    "    \n",
    "    print('epoch {}/{}, train loss {}, test loss {}'.format(epoch+1, num_epochs, train_loss_epoch, test_loss_epoch)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2dgWDldspd_"
   },
   "outputs": [],
   "source": [
    "#torch.save(net, 'checkpoint_rg2.pt')\n",
    "torch.save(net.state_dict(), 'checkpoint_sd.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 4, 240, 240),\n",
      "      %down1.0.weight : Float(64, 4, 3, 3),\n",
      "      %down1.0.bias : Float(64),\n",
      "      %down1.1.weight : Float(64),\n",
      "      %down1.1.bias : Float(64),\n",
      "      %down1.1.running_mean : Float(64),\n",
      "      %down1.1.running_var : Float(64),\n",
      "      %down1.3.weight : Float(64, 64, 3, 3),\n",
      "      %down1.3.bias : Float(64),\n",
      "      %down1.4.weight : Float(64),\n",
      "      %down1.4.bias : Float(64),\n",
      "      %down1.4.running_mean : Float(64),\n",
      "      %down1.4.running_var : Float(64),\n",
      "      %down2.down.1.weight : Float(128, 64, 3, 3),\n",
      "      %down2.down.1.bias : Float(128),\n",
      "      %down2.down.2.weight : Float(128),\n",
      "      %down2.down.2.bias : Float(128),\n",
      "      %down2.down.2.running_mean : Float(128),\n",
      "      %down2.down.2.running_var : Float(128),\n",
      "      %down2.down.4.weight : Float(128, 128, 3, 3),\n",
      "      %down2.down.4.bias : Float(128),\n",
      "      %down2.down.5.weight : Float(128),\n",
      "      %down2.down.5.bias : Float(128),\n",
      "      %down2.down.5.running_mean : Float(128),\n",
      "      %down2.down.5.running_var : Float(128),\n",
      "      %down3.down.1.weight : Float(256, 128, 3, 3),\n",
      "      %down3.down.1.bias : Float(256),\n",
      "      %down3.down.2.weight : Float(256),\n",
      "      %down3.down.2.bias : Float(256),\n",
      "      %down3.down.2.running_mean : Float(256),\n",
      "      %down3.down.2.running_var : Float(256),\n",
      "      %down3.down.4.weight : Float(256, 256, 3, 3),\n",
      "      %down3.down.4.bias : Float(256),\n",
      "      %down3.down.5.weight : Float(256),\n",
      "      %down3.down.5.bias : Float(256),\n",
      "      %down3.down.5.running_mean : Float(256),\n",
      "      %down3.down.5.running_var : Float(256),\n",
      "      %down4.down.1.weight : Float(512, 256, 3, 3),\n",
      "      %down4.down.1.bias : Float(512),\n",
      "      %down4.down.2.weight : Float(512),\n",
      "      %down4.down.2.bias : Float(512),\n",
      "      %down4.down.2.running_mean : Float(512),\n",
      "      %down4.down.2.running_var : Float(512),\n",
      "      %down4.down.4.weight : Float(512, 512, 3, 3),\n",
      "      %down4.down.4.bias : Float(512),\n",
      "      %down4.down.5.weight : Float(512),\n",
      "      %down4.down.5.bias : Float(512),\n",
      "      %down4.down.5.running_mean : Float(512),\n",
      "      %down4.down.5.running_var : Float(512),\n",
      "      %even5.down.1.weight : Float(1024, 512, 3, 3),\n",
      "      %even5.down.1.bias : Float(1024),\n",
      "      %even5.down.2.weight : Float(1024),\n",
      "      %even5.down.2.bias : Float(1024),\n",
      "      %even5.down.2.running_mean : Float(1024),\n",
      "      %even5.down.2.running_var : Float(1024),\n",
      "      %even5.down.4.weight : Float(1024, 1024, 3, 3),\n",
      "      %even5.down.4.bias : Float(1024),\n",
      "      %even5.down.5.weight : Float(1024),\n",
      "      %even5.down.5.bias : Float(1024),\n",
      "      %even5.down.5.running_mean : Float(1024),\n",
      "      %even5.down.5.running_var : Float(1024),\n",
      "      %up4.up.weight : Float(1024, 512, 2, 2),\n",
      "      %up4.up.bias : Float(512),\n",
      "      %up4.conv.0.weight : Float(512, 1024, 3, 3),\n",
      "      %up4.conv.0.bias : Float(512),\n",
      "      %up4.conv.1.weight : Float(512),\n",
      "      %up4.conv.1.bias : Float(512),\n",
      "      %up4.conv.1.running_mean : Float(512),\n",
      "      %up4.conv.1.running_var : Float(512),\n",
      "      %up4.conv.3.weight : Float(512, 512, 3, 3),\n",
      "      %up4.conv.3.bias : Float(512),\n",
      "      %up4.conv.4.weight : Float(512),\n",
      "      %up4.conv.4.bias : Float(512),\n",
      "      %up4.conv.4.running_mean : Float(512),\n",
      "      %up4.conv.4.running_var : Float(512),\n",
      "      %up3.up.weight : Float(512, 256, 2, 2),\n",
      "      %up3.up.bias : Float(256),\n",
      "      %up3.conv.0.weight : Float(256, 512, 3, 3),\n",
      "      %up3.conv.0.bias : Float(256),\n",
      "      %up3.conv.1.weight : Float(256),\n",
      "      %up3.conv.1.bias : Float(256),\n",
      "      %up3.conv.1.running_mean : Float(256),\n",
      "      %up3.conv.1.running_var : Float(256),\n",
      "      %up3.conv.3.weight : Float(256, 256, 3, 3),\n",
      "      %up3.conv.3.bias : Float(256),\n",
      "      %up3.conv.4.weight : Float(256),\n",
      "      %up3.conv.4.bias : Float(256),\n",
      "      %up3.conv.4.running_mean : Float(256),\n",
      "      %up3.conv.4.running_var : Float(256),\n",
      "      %up2.up.weight : Float(256, 128, 2, 2),\n",
      "      %up2.up.bias : Float(128),\n",
      "      %up2.conv.0.weight : Float(128, 256, 3, 3),\n",
      "      %up2.conv.0.bias : Float(128),\n",
      "      %up2.conv.1.weight : Float(128),\n",
      "      %up2.conv.1.bias : Float(128),\n",
      "      %up2.conv.1.running_mean : Float(128),\n",
      "      %up2.conv.1.running_var : Float(128),\n",
      "      %up2.conv.3.weight : Float(128, 128, 3, 3),\n",
      "      %up2.conv.3.bias : Float(128),\n",
      "      %up2.conv.4.weight : Float(128),\n",
      "      %up2.conv.4.bias : Float(128),\n",
      "      %up2.conv.4.running_mean : Float(128),\n",
      "      %up2.conv.4.running_var : Float(128),\n",
      "      %up1.up.weight : Float(128, 64, 2, 2),\n",
      "      %up1.up.bias : Float(64),\n",
      "      %up1.conv.0.weight : Float(64, 128, 3, 3),\n",
      "      %up1.conv.0.bias : Float(64),\n",
      "      %up1.conv.1.weight : Float(64),\n",
      "      %up1.conv.1.bias : Float(64),\n",
      "      %up1.conv.1.running_mean : Float(64),\n",
      "      %up1.conv.1.running_var : Float(64),\n",
      "      %up1.conv.3.weight : Float(64, 64, 3, 3),\n",
      "      %up1.conv.3.bias : Float(64),\n",
      "      %up1.conv.4.weight : Float(64),\n",
      "      %up1.conv.4.bias : Float(64),\n",
      "      %up1.conv.4.running_mean : Float(64),\n",
      "      %up1.conv.4.running_var : Float(64),\n",
      "      %out.0.weight : Float(1, 64, 1, 1),\n",
      "      %out.0.bias : Float(1)):\n",
      "  %137 : Float(1, 64, 238, 238) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%input.1, %down1.0.weight, %down1.0.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %138 : Float(1, 64, 238, 238) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%137, %down1.1.weight, %down1.1.bias, %down1.1.running_mean, %down1.1.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %139 : Float(1, 64, 238, 238) = onnx::Relu(%138) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %140 : Float(1, 64, 236, 236) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%139, %down1.3.weight, %down1.3.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %141 : Float(1, 64, 236, 236) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%140, %down1.4.weight, %down1.4.bias, %down1.4.running_mean, %down1.4.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %142 : Float(1, 64, 236, 236) = onnx::Relu(%141) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %143 : Float(1, 64, 118, 118) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%142) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %144 : Float(1, 128, 118, 118) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %down2.down.1.weight, %down2.down.1.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %145 : Float(1, 128, 118, 118) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%144, %down2.down.2.weight, %down2.down.2.bias, %down2.down.2.running_mean, %down2.down.2.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %146 : Float(1, 128, 118, 118) = onnx::Relu(%145) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %147 : Float(1, 128, 118, 118) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%146, %down2.down.4.weight, %down2.down.4.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %148 : Float(1, 128, 118, 118) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%147, %down2.down.5.weight, %down2.down.5.bias, %down2.down.5.running_mean, %down2.down.5.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %149 : Float(1, 128, 118, 118) = onnx::Relu(%148) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %150 : Float(1, 128, 59, 59) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%149) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %151 : Float(1, 256, 59, 59) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%150, %down3.down.1.weight, %down3.down.1.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %152 : Float(1, 256, 59, 59) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%151, %down3.down.2.weight, %down3.down.2.bias, %down3.down.2.running_mean, %down3.down.2.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %153 : Float(1, 256, 59, 59) = onnx::Relu(%152) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %154 : Float(1, 256, 59, 59) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%153, %down3.down.4.weight, %down3.down.4.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %155 : Float(1, 256, 59, 59) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%154, %down3.down.5.weight, %down3.down.5.bias, %down3.down.5.running_mean, %down3.down.5.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %156 : Float(1, 256, 59, 59) = onnx::Relu(%155) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %157 : Float(1, 256, 29, 29) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%156) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %158 : Float(1, 512, 29, 29) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%157, %down4.down.1.weight, %down4.down.1.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %159 : Float(1, 512, 29, 29) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%158, %down4.down.2.weight, %down4.down.2.bias, %down4.down.2.running_mean, %down4.down.2.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %160 : Float(1, 512, 29, 29) = onnx::Relu(%159) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %161 : Float(1, 512, 29, 29) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%160, %down4.down.4.weight, %down4.down.4.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %162 : Float(1, 512, 29, 29) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%161, %down4.down.5.weight, %down4.down.5.bias, %down4.down.5.running_mean, %down4.down.5.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %163 : Float(1, 512, 29, 29) = onnx::Relu(%162) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %164 : Float(1, 512, 14, 14) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%163) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %165 : Float(1, 1024, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%164, %even5.down.1.weight, %even5.down.1.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %166 : Float(1, 1024, 14, 14) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%165, %even5.down.2.weight, %even5.down.2.bias, %even5.down.2.running_mean, %even5.down.2.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %167 : Float(1, 1024, 14, 14) = onnx::Relu(%166) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %168 : Float(1, 1024, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%167, %even5.down.4.weight, %even5.down.4.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %169 : Float(1, 1024, 14, 14) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%168, %even5.down.5.weight, %even5.down.5.bias, %even5.down.5.running_mean, %even5.down.5.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %170 : Float(1, 1024, 14, 14) = onnx::Relu(%169) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %171 : Float(1, 512, 28, 28) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%170, %up4.up.weight, %up4.up.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:794:0\n",
      "  %172 : Float(1, 512, 29, 29) = onnx::Pad[mode=\"reflect\", pads=[0, 0, 0, 0, 0, 0, 1, 1]](%171) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:3408:0\n",
      "  %173 : Float(1, 1024, 29, 29) = onnx::Concat[axis=1](%172, %163) # <ipython-input-59-02912fc89991>:53:0\n",
      "  %174 : Float(1, 512, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%173, %up4.conv.0.weight, %up4.conv.0.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %175 : Float(1, 512, 27, 27) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%174, %up4.conv.1.weight, %up4.conv.1.bias, %up4.conv.1.running_mean, %up4.conv.1.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %176 : Float(1, 512, 27, 27) = onnx::Relu(%175) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %177 : Float(1, 512, 25, 25) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%176, %up4.conv.3.weight, %up4.conv.3.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %178 : Float(1, 512, 25, 25) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%177, %up4.conv.4.weight, %up4.conv.4.bias, %up4.conv.4.running_mean, %up4.conv.4.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %179 : Float(1, 512, 25, 25) = onnx::Relu(%178) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %180 : Float(1, 256, 50, 50) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%179, %up3.up.weight, %up3.up.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:794:0\n",
      "  %181 : Float(1, 256, 59, 59) = onnx::Pad[mode=\"reflect\", pads=[0, 0, 4, 4, 0, 0, 5, 5]](%180) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:3408:0\n",
      "  %182 : Float(1, 512, 59, 59) = onnx::Concat[axis=1](%181, %156) # <ipython-input-59-02912fc89991>:53:0\n",
      "  %183 : Float(1, 256, 57, 57) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%182, %up3.conv.0.weight, %up3.conv.0.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %184 : Float(1, 256, 57, 57) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%183, %up3.conv.1.weight, %up3.conv.1.bias, %up3.conv.1.running_mean, %up3.conv.1.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %185 : Float(1, 256, 57, 57) = onnx::Relu(%184) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %186 : Float(1, 256, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%185, %up3.conv.3.weight, %up3.conv.3.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %187 : Float(1, 256, 55, 55) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%186, %up3.conv.4.weight, %up3.conv.4.bias, %up3.conv.4.running_mean, %up3.conv.4.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %188 : Float(1, 256, 55, 55) = onnx::Relu(%187) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %189 : Float(1, 128, 110, 110) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%188, %up2.up.weight, %up2.up.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:794:0\n",
      "  %190 : Float(1, 128, 118, 118) = onnx::Pad[mode=\"reflect\", pads=[0, 0, 4, 4, 0, 0, 4, 4]](%189) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:3408:0\n",
      "  %191 : Float(1, 256, 118, 118) = onnx::Concat[axis=1](%190, %149) # <ipython-input-59-02912fc89991>:53:0\n",
      "  %192 : Float(1, 128, 116, 116) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%191, %up2.conv.0.weight, %up2.conv.0.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %193 : Float(1, 128, 116, 116) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%192, %up2.conv.1.weight, %up2.conv.1.bias, %up2.conv.1.running_mean, %up2.conv.1.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %194 : Float(1, 128, 116, 116) = onnx::Relu(%193) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %195 : Float(1, 128, 114, 114) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%194, %up2.conv.3.weight, %up2.conv.3.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %196 : Float(1, 128, 114, 114) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%195, %up2.conv.4.weight, %up2.conv.4.bias, %up2.conv.4.running_mean, %up2.conv.4.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %197 : Float(1, 128, 114, 114) = onnx::Relu(%196) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %198 : Float(1, 64, 228, 228) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%197, %up1.up.weight, %up1.up.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:794:0\n",
      "  %199 : Float(1, 64, 236, 236) = onnx::Pad[mode=\"reflect\", pads=[0, 0, 4, 4, 0, 0, 4, 4]](%198) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:3408:0\n",
      "  %200 : Float(1, 128, 236, 236) = onnx::Concat[axis=1](%199, %142) # <ipython-input-59-02912fc89991>:53:0\n",
      "  %201 : Float(1, 64, 234, 234) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%200, %up1.conv.0.weight, %up1.conv.0.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %202 : Float(1, 64, 234, 234) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%201, %up1.conv.1.weight, %up1.conv.1.bias, %up1.conv.1.running_mean, %up1.conv.1.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %203 : Float(1, 64, 234, 234) = onnx::Relu(%202) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %204 : Float(1, 64, 232, 232) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%203, %up1.conv.3.weight, %up1.conv.3.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %205 : Float(1, 64, 232, 232) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%204, %up1.conv.4.weight, %up1.conv.4.bias, %up1.conv.4.running_mean, %up1.conv.4.running_var) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %206 : Float(1, 64, 232, 232) = onnx::Relu(%205) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %207 : Float(1, 1, 232, 232) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%206, %out.0.weight, %out.0.bias) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %208 : Float(1, 1, 240, 240) = onnx::Pad[mode=\"constant\", pads=[0, 0, 4, 4, 0, 0, 4, 4], value=0.](%207) # /home/tobias/.local/lib/python3.6/site-packages/torch/nn/functional.py:3391:0\n",
      "  return (%208)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def export_onnx(filename):\n",
    "    dummy_input = torch.randn(1, 4, 240, 240)\n",
    "    torch.onnx.export(net, dummy_input, filename, verbose=True)\n",
    "    \n",
    "export_onnx(\"net5.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "net2(1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
