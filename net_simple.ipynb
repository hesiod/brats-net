{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!curl --user dl-user https://static.miglix.eu/data/Task01_BrainTumour.tar | tar xf -'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!curl --user dl-user https://static.miglix.eu/data/Task01_BrainTumour.tar | tar xf -'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!curl -O --user dl-user https://static.miglix.eu/data/checkpoint_sd.pt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!curl -O --user dl-user https://static.miglix.eu/data/checkpoint_sd.pt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!rm -rf brats-net\\n!git clone https://github.com/hesiod/brats-net.git\\n!rm -f model\\n!ln -s brats-net/model .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!rm -rf brats-net\n",
    "!git clone https://github.com/hesiod/brats-net.git\n",
    "!rm -f model\n",
    "!ln -s brats-net/model .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/dave/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/dave/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting torch>=1.5.0 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 753.2MB 2.8kB/s ta 0:00:0111 0% |▎                               | 7.3MB 8.1MB/s eta 0:01:32    4% |█▌                              | 35.7MB 7.9MB/s eta 0:01:32    7% |██▎                             | 53.1MB 7.0MB/s eta 0:01:41    7% |██▍                             | 55.0MB 7.0MB/s eta 0:01:40[K    30% |█████████▉                      | 232.6MB 120.1MB/s eta 0:00:05    31% |██████████                      | 236.7MB 8.1MB/s eta 0:01:05    49% |███████████████▉                | 373.7MB 8.2MB/s eta 0:00:47    53% |█████████████████▎              | 405.9MB 8.1MB/s eta 0:00:43s eta 0:00:03    79% |█████████████████████████▌      | 599.9MB 8.2MB/s eta 0:00:19    83% |██████████████████████████▊     | 629.8MB 8.1MB/s eta 0:00:16    85% |███████████████████████████▌    | 647.2MB 8.2MB/s eta 0:00:13    96% |███████████████████████████████ | 728.1MB 8.1MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting tensorboard>=2.2.0 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 639kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.19.0 (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/16/476826a84d545424084499763248abbbdc73d065168efed9aa71cdf2a7dc/numpy-1.19.0-cp36-cp36m-manylinux1_x86_64.whl (13.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.5MB 155kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting nibabel>=3.1.0 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/8c/cf676b9b3cf69164ba0703a9dcb86ed895ab172e09bece4480db4f03fcce/nibabel-3.1.1-py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 585kB/s ta 0:00:0111\n",
      "\u001b[?25hCollecting tqdm>=4.47.0 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/46/62/7663894f67ac5a41a0d8812d78d9d2a9404124051885af9d77dc526fb399/tqdm-4.47.0-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 2.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting future (from torch>=1.5.0->-r requirements.txt (line 1))\n",
      "Collecting grpcio>=1.24.3 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/29/1bd649737e427a6bb850174293b4f2b72ab80dd49462142db9b81e1e5c7b/grpcio-1.30.0.tar.gz (19.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 19.7MB 108kB/s ta 0:00:0111\n",
      "\u001b[?25hCollecting six>=1.10.0 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 2.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/41/fa/60888a1d591db07bc9c17dce2bcfb9f00ac507c0a23ecb827e76feb8f816/setuptools-49.1.0-py3-none-any.whl (789kB)\n",
      "\u001b[K    100% |████████████████████████████████| 798kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/21/57/d706964a7e4056f3f2244e16705388c11631fbb53d3e2d2a2d0fbc24d470/google_auth-1.18.0-py2.py3-none-any.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
      "\u001b[K    100% |████████████████████████████████| 788kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26; python_version >= \"3\" (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.0 (from tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/05/9867ef8eafd12265267bee138fa2c46ebf34a276ea4cbe184cba4c606e8b/protobuf-3.12.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 625kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting packaging>=14.3 (from nibabel>=3.1.0->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 163kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3\" (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing>=2.0.2 (from packaging>=14.3->nibabel>=3.1.0->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: future, numpy, torch, six, grpcio, chardet, idna, urllib3, certifi, requests, setuptools, werkzeug, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, zipp, importlib-metadata, markdown, tensorboard-plugin-wit, absl-py, wheel, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, tensorboard, pyparsing, packaging, nibabel, tqdm\n",
      "  Running setup.py install for grpcio ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed absl-py-0.9.0 cachetools-4.1.1 certifi-2020.6.20 chardet-3.0.4 future-0.18.2 google-auth-1.18.0 google-auth-oauthlib-0.4.1 grpcio-1.30.0 idna-2.10 importlib-metadata-1.7.0 markdown-3.2.2 nibabel-3.1.1 numpy-1.19.0 oauthlib-3.1.0 packaging-20.4 protobuf-3.12.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-2.4.7 requests-2.24.0 requests-oauthlib-1.3.0 rsa-4.6 setuptools-49.1.0 six-1.15.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 torch-1.5.1 tqdm-4.47.0 urllib3-1.25.9 werkzeug-1.0.1 wheel-0.34.2 zipp-3.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as td\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.brats_dataset\n",
    "import model.unet\n",
    "import model.utils\n",
    "import model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, filename=None, criterion=None):\n",
    "        self.net = model.unet.Net()\n",
    "        if filename:\n",
    "            self.net.load_state_dict(torch.load(filename))\n",
    "        else:\n",
    "            self.net.apply(model.unet.init_weights)\n",
    "\n",
    "        self.device = model.utils.try_gpu()\n",
    "        print('Using device {}'.format(self.device))\n",
    "\n",
    "        self.run_iter = 0\n",
    "\n",
    "    def check_topology(self):\n",
    "        dummy_input = torch.randn(size=(2, 4, 240, 240), dtype=torch.float32)\n",
    "        y = self.net(dummy_input)\n",
    "\n",
    "\n",
    "    def export_onnx(self, filename):\n",
    "        dummy_input = torch.randn(1, 4, 240, 240)\n",
    "        torch.onnx.export(self.net, dummy_input, filename, verbose=True)\n",
    "\n",
    "class TrainContext:\n",
    "    def __init__(self, context, data_context, criterion, lr, batch_size, experiment_name='unnamed'):\n",
    "        self.ctx = context\n",
    "        self.data = data_context\n",
    "        self.global_iter = 1\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(self.ctx.net.parameters(), lr=lr)\n",
    "        #optimizer = torch.optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "        #self.scheduler = ReduceLROnPlateau(self.optimizer, 'min')\n",
    "\n",
    "    def run(self, num_epochs):\n",
    "        self.ctx.run_iter += 1\n",
    "        run_name = 'runs/run_{}_{}_{}'.format(self.experiment_name, lr, self.ctx.run_iter)\n",
    "\n",
    "        print('Commencing {}'.format(run_name))\n",
    "        self.writer = SummaryWriter(os.path.join('runs', run_name))\n",
    "\n",
    "        print('Writing graph')\n",
    "        dummy_input = torch.randn(size=(2, 4, 240, 240), dtype=torch.float32)\n",
    "        self.writer.add_graph(self.ctx.net, dummy_input)\n",
    "        del dummy_input\n",
    "        print('done')\n",
    "\n",
    "        self.ctx.net.to(self.ctx.device)\n",
    "\n",
    "        self.brats_train_perepoch = self.data.split_data(num_epochs)\n",
    "\n",
    "        for epoch in range(num_epochs-1):\n",
    "            self.run_epoch(epoch)\n",
    "\n",
    "        self.writer.close()\n",
    "\n",
    "    def checkpoint(self):\n",
    "        torch.save(self.ctx.net.state_dict(), 'checkpoints/checkpoint_{}_{}.pt'.format(self.experiment_name, self.ctx.run_iter))\n",
    "\n",
    "    def run_epoch(self, epoch):\n",
    "        train_iter = td.DataLoader(self.brats_train_perepoch[epoch], batch_size, shuffle=True, num_workers=num_workers)\n",
    "        test_iter = td.DataLoader(self.brats_train_perepoch[epoch+1], batch_size, shuffle=True, num_workers=num_workers)\n",
    "        #test_iter = td.DataLoader(brats_test, batch_size, shuffle=False, num_workers=num_workers)\n",
    "        \n",
    "        batch_count = len(train_iter)\n",
    "        \n",
    "        print('Total batches: {}'.format(batch_count))\n",
    "\n",
    "        train_loss_epoch = 0.0\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            batch_loss = self.run_batch(i, X, y)\n",
    "            train_loss_epoch += batch_loss\n",
    "            print('batch {:4}/{} batchloss {}'.format(i+1, batch_count, batch_loss))\n",
    "        train_loss_epoch /= batch_count\n",
    "\n",
    "        self.writer.add_scalar('loss/train', train_loss_epoch, self.global_iter)\n",
    "\n",
    "        self.ctx.net.eval()\n",
    "        test_loss_epoch = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in test_iter:\n",
    "                X_test = X_test.float().to(self.ctx.device)\n",
    "                y_test = y_test.float().to(self.ctx.device)\n",
    "                y_test_hat = self.ctx.net(X_test).squeeze(1)\n",
    "                b_l = self.criterion(y_test_hat, y_test)\n",
    "                test_loss_epoch += float(b_l)\n",
    "            test_loss_epoch /= len(test_iter)\n",
    "\n",
    "        self.writer.add_scalar('loss/test', test_loss_epoch, self.global_iter)\n",
    "        self.writer.flush()\n",
    "\n",
    "        self.checkpoint()\n",
    "\n",
    "\n",
    "        print('epoch {}/{}, train loss {}, test loss {}'.format(epoch+1,\n",
    "            num_epochs, self.train_loss_epoch, test_loss_epoch))\n",
    "\n",
    "    def run_batch(self, i, X, y):\n",
    "        self.global_iter += 1\n",
    "        self.ctx.net.train()\n",
    "\n",
    "        X = X.float().to(self.ctx.device)\n",
    "        y = y.float().to(self.ctx.device)\n",
    "        y_hat = self.ctx.net(X).squeeze(1)\n",
    "\n",
    "        l = self.criterion(y_hat, y)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        nn.utils.clip_grad_value_(self.ctx.net.parameters(), 0.1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        for tag, value in self.ctx.net.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            self.writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), self.global_iter)\n",
    "            self.writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), self.global_iter)\n",
    "\n",
    "        self.writer.add_scalar('loss/total_loss', float(l), self.global_iter)\n",
    "        self.writer.add_images('masks/0_base', X[:, 0:3, :, :], self.global_iter)\n",
    "        y_us = y.unsqueeze(1)\n",
    "        y_hat_us = y_hat.unsqueeze(1)\n",
    "        y_hat_us_sig = torch.sigmoid(y_hat_us) > 0.5\n",
    "        self.writer.add_images('masks/1_true', y_us, self.global_iter)\n",
    "        self.writer.add_images('masks/2_predicted', y_hat_us_sig, self.global_iter)\n",
    "        self.writer.add_images('extra/raw', y_hat_us, self.global_iter)\n",
    "        overlaid = torch.cat([y_hat_us_sig.float(), y_us, torch.zeros_like(y_us)], dim=1)\n",
    "        self.writer.add_images('extra/overlaid', overlaid, self.global_iter)\n",
    "\n",
    "        self.writer.flush()\n",
    "\n",
    "        return float(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 484 files\n",
      "Loaded 484 labels\n",
      "Loaded 266 files\n"
     ]
    }
   ],
   "source": [
    "dctx = model.brats_dataset.DataSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier for this group of runs\n",
    "meta_name = 'brats4'\n",
    "batch_size = 32\n",
    "num_workers = 6\n",
    "num_epochs = 50\n",
    "lr = 0.0001\n",
    "should_check = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "ctx = Context('checkpoint_sd.pt')\n",
    "\n",
    "if should_check:\n",
    "    # Check whether layer inputs/outputs dimensions are correct\n",
    "    # by conducting a test run\n",
    "    ctx.check_topology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.Tensor([5.0]).to(ctx.device)\n",
    "criterion = model.loss.Loss(pos_weight)\n",
    "\n",
    "tctx = TrainContext(ctx, dctx, criterion=criterion, lr=lr, batch_size=batch_size, experiment_name=meta_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing runs/run_brats4_0.0001_1\n",
      "Writing graph\n",
      "done\n",
      "total count = 65340, num_epochs = 50, per epoch = 1306\n",
      "Total batches: 41\n",
      "batch    1/41 batchloss -0.41140273213386536\n",
      "batch    2/41 batchloss -0.36365649104118347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a4a24d9fc523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-db8f2b59a774>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-db8f2b59a774>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtrain_loss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mtrain_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch {:4}/{} batchloss {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-db8f2b59a774>\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(self, i, X, y)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tctx.run(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.export_onnx(\"net5.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
